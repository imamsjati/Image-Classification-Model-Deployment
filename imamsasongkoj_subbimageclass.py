# -*- coding: utf-8 -*-
"""ImamSasongkoJ_SubbImageClass.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qUsuonFj5FS6OsWROw-K0fT-L2t10otT

## Image Classification Model Deployment
**Belajar Pengembangan Machine Learning**

**Imam Sasongko Jati**

Instalasi Package Kaggle
"""

!pip install -q kaggle

"""Upload file API dari akun Kaggle"""

# upload kaggle.json
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

"""Mendownload dataset berupa kumpulan gambar binatang dari Kaggle [teks link](https://https://www.kaggle.com/madisona/translated-animals10/version/1)"""

!kaggle datasets download -d madisona/translated-animals10

"""Membuat direktori baru sebagai tempat untuk mengunzip dataset"""

!mkdir datapict
!unzip -qq translated-animals10.zip -d datapict
!ls datapict

"""Instalasi Package tree digunakan untuk melihat susunan direktori"""

!sudo apt install tree

"""Melihat susunan direktori baru yang telah dibuat"""

!tree -d datapict/

"""Menghapus beberapa direktori dari dataset yang tidak diperlukan dalam pembuatan model"""

import shutil
#hapus direktori

shutil.rmtree('datapict/animals10/raw-img/cat')
shutil.rmtree('datapict/animals10/raw-img/cow')
shutil.rmtree('datapict/animals10/raw-img/dog')
shutil.rmtree('datapict/animals10/raw-img/elephant')
shutil.rmtree('datapict/animals10/raw-img/horse')
shutil.rmtree('datapict/animals10/raw-img/sheep')
shutil.rmtree('datapict/animals10/raw-img/squirrel')

"""Melihat susunan direktori yang baru"""

!tree -d datapict/

"""Instalasi Package tqdm untuk melakukan split direktori pada dataset"""

!pip install split_folders tqdm

"""Membagi dataset menjadi data train(80%) dan data validasi(20%)"""

import splitfolders

splitfolders.ratio('datapict/animals10/raw-img/', output='datapict/animals10/raw-img/data_model', seed=3, ratio=(.8, .2))

import os

#Direktori Utama
base_dir = 'datapict/animals10/raw-img/data_model'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')
#Direktori Train
train_butterfly_dir = os.path.join(train_dir, 'butterfly')
train_chicken_dir = os.path.join(train_dir, 'chicken')
train_spider_dir = os.path.join(train_dir, 'spider')
#Direktori Validasi
validation_butterfly_dir = os.path.join(validation_dir, 'butterfly')
validation_chicken_dir = os.path.join(validation_dir, 'chicken')
validation_spider_dir = os.path.join(validation_dir, 'spider')

"""Mencetak 2 gambar secara acak dari masing-masing direktori train"""

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random

butterfly_files = os.listdir(train_butterfly_dir)
chicken_files = os.listdir(train_chicken_dir)
spider_files = os.listdir(train_spider_dir)

pic_index = random.randrange(0, 1000)

next_butterfly = [os.path.join(train_butterfly_dir, fname) 
                for fname in butterfly_files[pic_index-2:pic_index]]
next_chicken = [os.path.join(train_chicken_dir, fname) 
                for fname in chicken_files[pic_index-2:pic_index]]
next_spider = [os.path.join(train_spider_dir, fname) 
                for fname in spider_files[pic_index-2:pic_index]]

for i, img_path in enumerate(next_butterfly+next_chicken+next_spider):
  img = mpimg.imread(img_path)
  plt.imshow(img)
  plt.axis('Off')
  plt.show()

"""Instalasi Package TensorFlow"""

import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator

print(tf.__version__)

"""Membuat objek ImageDataGenerator untuk data training dan data validasi"""

train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=40,
                    width_shift_range=0.2,
                    height_shift_range=0.2,
                    zoom_range=0.2,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')
 
test_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=40,
                    width_shift_range=0.2,
                    height_shift_range=0.2,
                    zoom_range=0.2,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

"""Dengan objek ImageDataGenerator yang telah dibuat, dilakukan persiapan untuk data latih yang akan digunakan untuk melatih model yang dibuat."""

train_generator = train_datagen.flow_from_directory(
        train_dir,  # direktori data latih
        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        batch_size=20,
        class_mode='categorical')
 
validation_generator = test_datagen.flow_from_directory(
        validation_dir, # direktori data validasi
        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel
        batch_size=20, 
        class_mode='categorical')

"""Data telah siap dan dilanjutkan dengan membangun arsitektur CNN dengan model sekuensial."""

tf.device('/device:GPU:0')

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5), 
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

"""Memasukkan fungsi compile pada objek model dengan loss function menggunakan 'categorical_crossentropy' dan optimizer 'adam'"""

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

"""Membuat fungsi callback yang akan membuat proses training akan berhenti ketika kondisi akurasi tercapai"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.80 and logs.get('val_accuracy')>0.80):
      print("\nAkurasi diatas 80%, training selesai!")
      self.model.stop_training = True

callbacks = myCallback()

history = model.fit(train_generator, 
                    epochs = 50, 
                    steps_per_epoch = 32,
                    validation_data = validation_generator, 
                    validation_steps = 8,
                    verbose = 1,
                    callbacks = [callbacks])

"""Membuat plot akurasi"""

import numpy as np
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""Membuat plot loss"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

"""Mencetak file .tflite"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)

!ls -la | grep 'model'